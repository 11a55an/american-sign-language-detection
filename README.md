# American Sign Language Detection Model using YOLOv7 and Google Colab

This repository contains a model for detecting the 26 alphabetic letters from American Sign Language (ASL) using YOLOv7. The model is built and trained using Python, YOLOv7, and Google Colab.

## Table of Contents
- [Introduction](#introduction)
- [Features](#features)
- [Requirements](#requirements)
- [Usage](#usage)

## Introduction

The American Sign Language Detection Model is a machine learning project designed to detect and recognize the 26 alphabetic letters from American Sign Language (ASL) using the YOLOv7 architecture. The model is built using Python and various machine learning libraries and is trained using a dataset of ASL images.

## Features

- **ASL Alphabet Detection**: Recognizes and detects the 26 letters of the ASL alphabet.
- **YOLOv7 Model**: Utilizes YOLOv7, a state-of-the-art object detection model.
- **Google Colab Integration**: The model is trained using Google Colab for easy collaboration and access to GPU resources.

## Requirements

- Python 3.x
- YOLOv7
- Google Colab or a local machine with a GPU

## Usage

1. Clone the repository and navigate to the project directory:

    ```bash
    git clone https://github.com/11a55an/american-sign-language-detection.git
    cd asl-yolov7
    ```

2. Open the provided notebook for the American Sign Language Detection Model.

3. Follow the instructions in the notebook to load the dataset, preprocess the data, configure YOLOv7, train the model, and make predictions.

4. Evaluate the model's performance and make predictions on new ASL images.
